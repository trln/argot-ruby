# Argot : a Ruby gem for TRLN shared discovery ingest processes

This gem provides libraries and command-line utilities for working with Argot, the ingest format for
the TRLN shared index.

# Installation

Start with

    $ bundle install

(as long as you have the `bundler` gem available) will install all the dependencies. then


    $ bundle exec rake spec

or even just

    $ bundle exec rake

Will run the tests.

    $ bundle exec rake install 
    
will install the gem.

This gem is supported under both MRI and JRuby, but for small input files
especially, MRI is likely to be faster.  No optimizations are yet in place to
take advantage of multithreading under JRuby.

## Usage 

### As Library
```ruby

require 'json' # only required for the example
require 'argot'

# new reader for processing files in the Argot format
# with default validator using rules in  `lib/data/rules.yml`
# with default error handler that writes bad records and the error report
# to stdout

File.open("nccu-2015101201320.json") do |f|
    reader = Argot::Reader.new(f)
    File.open( "some-output.dat" ) do |output|
        reader.each do |rec|
            output.write(rec.to_json)if rec['id'].start_with?("NCCU")
        end
    end
end
```

## CLI

After installing the gem, you can run `argot help` to see the available
commands.  The 'validate' commands are described more fully below, but if you
want to see what 'flattened' and 'flattend and suffixed' Argot look like you
can run `argot flatten` or `argot suffix`, respectively, on raw Argot output.  

### Inputs and Outputs

Many commands accept input and output either from/to named files, or from STDIN and STDOUT, where omitting the `input` argument (or using the `-` shortcut) will read from STDIN, while omitting the output argument will output to STDOUT.

e.g 

    $ argot flatten < argot-notflat.json > argot-flat.json    

and

    $ argot flatten argot-notflat.json argot-flat.json    

are equivalent, but you can also do something like:

    $ my_argot_maker_that_ouputs_to_stdout | argot flatten | jq 

to avoid creating intermediate files.

If you want to read from STDIN but output to a named file, use `-` as the first argument, e.g. 

    $ my_argot_maker_that_writes_to_stdout | argot flatten - flattened.json

## Splitting Large Files

To aid in creating ingest packages of a manageable size, the tool has a `split` command that takes one or more input files and writes the records in them to a series of output files that have a maximum size, e.g. if `large-argot.json` has 253,000 records, then


    $ argot split large-argot.json

Will create `add-argot-1.json, add-argot-2.json .... add-argot-13.json` in the
`argot-files` subdirectory of the current working directory (configurable via
option), where the first 12 will have 20,000 records each and the last will
have 13,000 records.  The chunk size is also configurable via option.

## Validation

    $ argot validate [input] [output]

Runs basic quality checks on the records in `input`, writing records that pass to `output`, and error messages to STDERR.  This lets you use `argot validate` as a filter, e.g.

    $ argot validate my_argot.json valid_argot.json

will result in only valid documents in `valid_argot.json`.  Note that if you use the `--all` switch (see below) the output is documents that are flattened,
suffixed, and Solr-valid, which are not suitable for ingest.  There is currently no support for retaining the original Argot in this mode.

If you just want to run the checks and not have the 'good' records appear in output, add the `-q` or `--quiet` option.

To run a full check against Argot output generated from `marc-to-argot` to the Solr documents as they are generated by `trln-ingest` application, you can run
`validate` with the `--all` or `-a` switch, which is an alias for the 
`full_validate` command.  Note that the `full_validate` command always uses
thebundled solr schema (see below).

To aid in low-level debugging, there is a `solrvalidate` command:

    $ argot solrvalidate flattened-and-suffixed-document.json

Attempts to validate a flattened and suffixed (i.e. ready to be sent to Solr)
document against the schema.  Currently, this mostly involves checking that
single-valued fields do not have multiple values, and that numeric and date
fields match the formats required for Solr fields.  This command will exit with
an error status if any of the documents fail to validate.  If you want the
valid documents to be sent to STDOUT, pass in the `-c/--cull` option.

The schema used in `solrvalidate` is loaded from in order of preference:

1. `.argot-solr-schema.xml` in the current working directory
1. `.argot-solr-schema.xml` in the user's home directory
1. The `solr_schema.xml` bundled with the gem (`lib/data/solr_schema.xml` in the repository)

You may also specify a location on the filesystem or the base URL of the Solr
collection (e.g. `https://localhost:8983/solr/trlnbib`) to read the schema
from; this is mostly helpful for when the schema has changed and you're trying
to see whether a document's validation status is affected.

You may download a fresh copy of the schema and store it in the first of the
above listed locations (allowing you to copy it to the user's home directory,
if you so choose) by using the `schemaupdate` command.

## Ingest (Development only)

Sometimes you'll want to ingest your Argot files directly into Solr, e.g. when your'e developing a new feature and don't want to set up an ingest application.

    $ argot ingest some-argot.json 

Will flatten and suffix the records in the named files and send them to
`http://localhost:8983/solr/trln`.  You can configure the URL and size of the
batches in which documents are committed to Solr via options.  See `argot help
ingest` for more details.

## Documentation

To build the documentation, I suggest YARD.

    $ gem install yard
    $ gem install redcarpet # may need a different markdown parser under jruby
    $ yard

This will create files in `doc/`

## Dependencies (Gems)

All Platforms:

 * [`traject`](https://github.com/traject/traject)

### MRI

 * [`yajl-ruby`](https://github.com/brianmario/yajl-ruby) -- JSON support
 
To support this, you'll need the `yajl` system package installed.

### JRuby

 * `jar-dependencies` 

Also uses `noggit`, the Java-based JSON parser from Solr, to process JSON;
import and use should be handled for you automatically.
